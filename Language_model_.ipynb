{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import jieba\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './movie_comments.csv'\n",
    "content = pd.read_csv(filename,low_memory = False)\n",
    "comments = content.comment.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanTokens(string):\n",
    "    return re.findall('\\w+',string)\n",
    "comments_clean = [''.join(cleanTokens(str(line))) for line in comments]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_str(string):\n",
    "    return jieba.lcut(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENS_raw = [cut_str(lines) for lines in comments_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENS = []\n",
    "for word in TOKENS_raw:\n",
    "    TOKENS += word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENS_two_words = [TOKENS[i-1]+word for i,word in enumerate(TOKENS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_word_one = Counter(TOKENS)\n",
    "count_word_two = Counter(TOKENS_two_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_1(word):\n",
    "    return count_word_one[word]/len(TOKENS)\n",
    "def prob_2(word1,word2):\n",
    "    if word1+word2 in TOKENS_two_words: \n",
    "        return count_word_two[word1+word2]/count_word_one[word1]\n",
    "    else: \n",
    "        return 1/len(TOKENS_two_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0035971223021582736"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_2('吴京','厉害')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probility(sentence):\n",
    "    words = cut_str(sentence)\n",
    "    prob_sentence = 1.0\n",
    "    for i,word in enumerate(words):\n",
    "        \n",
    "        prob_sentence =prob_2(words[i-1],word)* prob_sentence\n",
    "    \n",
    "    return prob_sentence\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1965403318039716e-31"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probility(comments_clean[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
